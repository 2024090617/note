{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce592b8",
   "metadata": {},
   "source": [
    "# Knowledge Notebook Tutorial\n",
    "\n",
    "This tutorial shows you how to efficiently organize and manage notes across multiple categories using the Knowledge Notebook API.\n",
    "\n",
    "## Features\n",
    "- ğŸ“ Create notes with tags for categorization (psychology, CS, AI, etc.)\n",
    "- ğŸ” Semantic search powered by multilingual embeddings\n",
    "- ğŸ“š Version tracking for all note updates\n",
    "- âœ… Verification status management\n",
    "- ğŸ·ï¸ Tag-based filtering and organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e8703",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, make sure the API server is running:\n",
    "```bash\n",
    "cd /Users/zhangzuohai/Documents/workspace/note/knowledge-base\n",
    "uvicorn src.notebook.api:app --reload\n",
    "```\n",
    "\n",
    "Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0068e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Status: {'status': 'ok', 'collection': 'notebook'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "# Helper function for pretty printing\n",
    "def print_json(data):\n",
    "    print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Test connection\n",
    "response = requests.get(f\"{BASE_URL}/health\")\n",
    "print(\"API Status:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c542b5",
   "metadata": {},
   "source": [
    "## 2. Create Notes by Category\n",
    "\n",
    "Use tags to organize notes into different categories. Tags make it easy to filter and find related notes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1795b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Psychology Note:\n",
      "{\n",
      "  \"note_id\": \"0e94029c-34a1-4fd8-9419-6a706a3d6f83\",\n",
      "  \"point_id\": \"4d3bb7fb-854c-4d7f-a9ad-cbad3115e532\",\n",
      "  \"latest\": {\n",
      "    \"point_id\": \"4d3bb7fb-854c-4d7f-a9ad-cbad3115e532\",\n",
      "    \"note_id\": \"0e94029c-34a1-4fd8-9419-6a706a3d6f83\",\n",
      "    \"version\": 1,\n",
      "    \"title\": \"K-means Unsupervised Clustering Overview\",\n",
      "    \"content\": \"K-means is an unsupervised clustering algorithm that partitions unlabeled data into K clusters by iteratively minimizing the within-cluster sum of squared distances (SSE). The algorithm alternates between assigning each data point to the nearest cluster center (based on distance, typically Euclidean) and recomputing each center as the mean of its assigned points. During each iteration, all points are reassigned from scratch and may move between clusters if another center becomes closer. Each iteration monotonically decreases or preserves SSE, guaranteeing convergence to a local optimum, though not necessarily the global optimum. Results depend on the initial centers, making the method sensitive to initialization and outliers. Common improvements include K-means++ initialization and multiple restarts. K-means works best for roughly spherical, similarly sized clusters and performs poorly on non-convex or unevenly distributed data.\",\n",
      "    \"tags\": [\n",
      "      \"computer-science\",\n",
      "      \"k-means\",\n",
      "      \"unsupervised-learning\",\n",
      "      \"clustering\"\n",
      "    ],\n",
      "    \"source_url\": \"ChatGPT\",\n",
      "    \"status\": \"unverified\",\n",
      "    \"created_at\": \"2026-01-07T16:10:31.254655+00:00\",\n",
      "    \"verified_at\": null,\n",
      "    \"attachments\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Psychology note\n",
    "psychology_note = {\n",
    "  \"title\": \"K-means Unsupervised Clustering Overview\",\n",
    "  \"content\": \"K-means is an unsupervised clustering algorithm that partitions unlabeled data into K clusters by iteratively minimizing the within-cluster sum of squared distances (SSE). The algorithm alternates between assigning each data point to the nearest cluster center (based on distance, typically Euclidean) and recomputing each center as the mean of its assigned points. During each iteration, all points are reassigned from scratch and may move between clusters if another center becomes closer. Each iteration monotonically decreases or preserves SSE, guaranteeing convergence to a local optimum, though not necessarily the global optimum. Results depend on the initial centers, making the method sensitive to initialization and outliers. Common improvements include K-means++ initialization and multiple restarts. K-means works best for roughly spherical, similarly sized clusters and performs poorly on non-convex or unevenly distributed data.\",\n",
    "  \"tags\": [\"computer-science\",\"k-means\", \"unsupervised-learning\", \"clustering\"],\n",
    "  \"source_url\": \"ChatGPT\"\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/notes\", json=psychology_note)\n",
    "psych_result = response.json()\n",
    "print(\"Created Psychology Note:\")\n",
    "print_json(psych_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f29855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CS Note:\n",
      "{\n",
      "  \"note_id\": \"028c4239-0236-4225-a1b5-d3449b629c27\",\n",
      "  \"point_id\": \"0fd70f0c-190f-4c1a-b1f0-f4cbfe0dfb68\",\n",
      "  \"latest\": {\n",
      "    \"point_id\": \"0fd70f0c-190f-4c1a-b1f0-f4cbfe0dfb68\",\n",
      "    \"note_id\": \"028c4239-0236-4225-a1b5-d3449b629c27\",\n",
      "    \"version\": 1,\n",
      "    \"title\": \"åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„CAPå®šç†\",\n",
      "    \"content\": \"\\nCAPå®šç†æŒ‡å‡ºï¼Œåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä»¥ä¸‹ä¸‰ä¸ªç‰¹æ€§æœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä¸¤ä¸ªï¼š\\n\\n**C (Consistency)**: ä¸€è‡´æ€§ - æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶é—´çœ‹åˆ°ç›¸åŒçš„æ•°æ®\\n**A (Availability)**: å¯ç”¨æ€§ - æ¯ä¸ªè¯·æ±‚éƒ½èƒ½å¾—åˆ°å“åº”ï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰\\n**P (Partition Tolerance)**: åˆ†åŒºå®¹é”™æ€§ - ç³»ç»Ÿåœ¨ç½‘ç»œåˆ†åŒºæ—¶ä»èƒ½ç»§ç»­è¿è¡Œ\\n\\nå®é™…åº”ç”¨ï¼š\\n- CPç³»ç»Ÿï¼šMongoDB, HBase - ç‰ºç‰²å¯ç”¨æ€§ä¿è¯ä¸€è‡´æ€§\\n- APç³»ç»Ÿï¼šCassandra, DynamoDB - ç‰ºç‰²å¼ºä¸€è‡´æ€§ä¿è¯å¯ç”¨æ€§\\n- CAç³»ç»Ÿï¼šä¼ ç»Ÿå…³ç³»æ•°æ®åº“ - åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ä¸ç°å®\\n    \",\n",
      "    \"tags\": [\n",
      "      \"computer-science\",\n",
      "      \"distributed-systems\",\n",
      "      \"theory\"\n",
      "    ],\n",
      "    \"source_url\": null,\n",
      "    \"status\": \"unverified\",\n",
      "    \"created_at\": \"2026-01-01T15:25:25.026739+00:00\",\n",
      "    \"verified_at\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Computer Science note\n",
    "cs_note = {\n",
    "    \"title\": \"åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„CAPå®šç†\",\n",
    "    \"content\": \"\"\"\n",
    "CAPå®šç†æŒ‡å‡ºï¼Œåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä»¥ä¸‹ä¸‰ä¸ªç‰¹æ€§æœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä¸¤ä¸ªï¼š\n",
    "\n",
    "**C (Consistency)**: ä¸€è‡´æ€§ - æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶é—´çœ‹åˆ°ç›¸åŒçš„æ•°æ®\n",
    "**A (Availability)**: å¯ç”¨æ€§ - æ¯ä¸ªè¯·æ±‚éƒ½èƒ½å¾—åˆ°å“åº”ï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰\n",
    "**P (Partition Tolerance)**: åˆ†åŒºå®¹é”™æ€§ - ç³»ç»Ÿåœ¨ç½‘ç»œåˆ†åŒºæ—¶ä»èƒ½ç»§ç»­è¿è¡Œ\n",
    "\n",
    "å®é™…åº”ç”¨ï¼š\n",
    "- CPç³»ç»Ÿï¼šMongoDB, HBase - ç‰ºç‰²å¯ç”¨æ€§ä¿è¯ä¸€è‡´æ€§\n",
    "- APç³»ç»Ÿï¼šCassandra, DynamoDB - ç‰ºç‰²å¼ºä¸€è‡´æ€§ä¿è¯å¯ç”¨æ€§\n",
    "- CAç³»ç»Ÿï¼šä¼ ç»Ÿå…³ç³»æ•°æ®åº“ - åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ä¸ç°å®\n",
    "    \"\"\",\n",
    "    \"tags\": [\"computer-science\", \"distributed-systems\", \"theory\"],\n",
    "    \"source_url\": None\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/notes\", json=cs_note)\n",
    "cs_result = response.json()\n",
    "print(\"Created CS Note:\")\n",
    "print_json(cs_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20561f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created AI Note:\n",
      "{\n",
      "  \"note_id\": \"08215693-4f4e-4e70-857b-b4dff0026b01\",\n",
      "  \"point_id\": \"2e70408c-a5d0-459a-902c-67cd1e6231c4\",\n",
      "  \"latest\": {\n",
      "    \"point_id\": \"2e70408c-a5d0-459a-902c-67cd1e6231c4\",\n",
      "    \"note_id\": \"08215693-4f4e-4e70-857b-b4dff0026b01\",\n",
      "    \"version\": 1,\n",
      "    \"title\": \"Transformer Architectureæ ¸å¿ƒæœºåˆ¶\",\n",
      "    \"content\": \"\\nTransformeræ˜¯ç°ä»£NLPçš„åŸºç¡€æ¶æ„ï¼Œç”±Vaswaniç­‰äººåœ¨2017å¹´æå‡º(\\\"Attention is All You Need\\\")ã€‚\\n\\næ ¸å¿ƒç»„ä»¶ï¼š\\n1. **Self-Attentionæœºåˆ¶**ï¼šè®¡ç®—åºåˆ—ä¸­æ¯ä¸ªä½ç½®ä¸å…¶ä»–ä½ç½®çš„ç›¸å…³æ€§\\n   - Query, Key, Valueä¸‰ä¸ªå‘é‡\\n   - Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V\\n\\n2. **Multi-Head Attention**ï¼šå¹¶è¡Œè¿è¡Œå¤šä¸ªattentionï¼Œæ•è·ä¸åŒç±»å‹çš„å…³ç³»\\n\\n3. **Position Encoding**ï¼šç”±äºæ²¡æœ‰RNNçš„é¡ºåºæ€§ï¼Œéœ€è¦é¢å¤–ç¼–ç ä½ç½®ä¿¡æ¯\\n\\n4. **Feed-Forward Networks**ï¼šæ¯ä¸ªä½ç½®ç‹¬ç«‹çš„å…¨è¿æ¥å±‚\\n\\nä¼˜åŠ¿ï¼š\\n- å¹¶è¡Œè®¡ç®—ï¼Œè®­ç»ƒé€Ÿåº¦å¿«\\n- èƒ½å¤Ÿæ•è·é•¿è·ç¦»ä¾èµ–\\n- å¯è§£é‡Šæ€§å¼ºï¼ˆå¯è§†åŒ–attentionæƒé‡ï¼‰\\n\\nåº”ç”¨ï¼šBERT, GPT, T5, Claudeç­‰å¤§æ¨¡å‹éƒ½åŸºäºTransformer\\n    \",\n",
      "    \"tags\": [\n",
      "      \"ai\",\n",
      "      \"machine-learning\",\n",
      "      \"deep-learning\",\n",
      "      \"nlp\"\n",
      "    ],\n",
      "    \"source_url\": \"https://arxiv.org/abs/1706.03762\",\n",
      "    \"status\": \"unverified\",\n",
      "    \"created_at\": \"2026-01-01T15:25:54.231552+00:00\",\n",
      "    \"verified_at\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example 3: AI/Machine Learning note\n",
    "ai_note = {\n",
    "    \"title\": \"Transformer Architectureæ ¸å¿ƒæœºåˆ¶\",\n",
    "    \"content\": \"\"\"\n",
    "Transformeræ˜¯ç°ä»£NLPçš„åŸºç¡€æ¶æ„ï¼Œç”±Vaswaniç­‰äººåœ¨2017å¹´æå‡º(\"Attention is All You Need\")ã€‚\n",
    "\n",
    "æ ¸å¿ƒç»„ä»¶ï¼š\n",
    "1. **Self-Attentionæœºåˆ¶**ï¼šè®¡ç®—åºåˆ—ä¸­æ¯ä¸ªä½ç½®ä¸å…¶ä»–ä½ç½®çš„ç›¸å…³æ€§\n",
    "   - Query, Key, Valueä¸‰ä¸ªå‘é‡\n",
    "   - Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V\n",
    "\n",
    "2. **Multi-Head Attention**ï¼šå¹¶è¡Œè¿è¡Œå¤šä¸ªattentionï¼Œæ•è·ä¸åŒç±»å‹çš„å…³ç³»\n",
    "\n",
    "3. **Position Encoding**ï¼šç”±äºæ²¡æœ‰RNNçš„é¡ºåºæ€§ï¼Œéœ€è¦é¢å¤–ç¼–ç ä½ç½®ä¿¡æ¯\n",
    "\n",
    "4. **Feed-Forward Networks**ï¼šæ¯ä¸ªä½ç½®ç‹¬ç«‹çš„å…¨è¿æ¥å±‚\n",
    "\n",
    "ä¼˜åŠ¿ï¼š\n",
    "- å¹¶è¡Œè®¡ç®—ï¼Œè®­ç»ƒé€Ÿåº¦å¿«\n",
    "- èƒ½å¤Ÿæ•è·é•¿è·ç¦»ä¾èµ–\n",
    "- å¯è§£é‡Šæ€§å¼ºï¼ˆå¯è§†åŒ–attentionæƒé‡ï¼‰\n",
    "\n",
    "åº”ç”¨ï¼šBERT, GPT, T5, Claudeç­‰å¤§æ¨¡å‹éƒ½åŸºäºTransformer\n",
    "    \"\"\",\n",
    "    \"tags\": [\"ai\", \"machine-learning\", \"deep-learning\", \"nlp\"],\n",
    "    \"source_url\": \"https://arxiv.org/abs/1706.03762\"\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/notes\", json=ai_note)\n",
    "ai_result = response.json()\n",
    "print(\"Created AI Note:\")\n",
    "print_json(ai_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14140b4d",
   "metadata": {},
   "source": [
    "## 3. Semantic Search\n",
    "\n",
    "The notebook uses multilingual embeddings to find similar notes based on meaning, not just keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb49ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results for: 'æ³¨æ„åŠ›æœºåˆ¶åœ¨ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨'\n",
      "Found 5 notes:\n",
      "\n",
      "1. Transformer Architectureæ ¸å¿ƒæœºåˆ¶ (score: 0.533)\n",
      "   Tags: ai, machine-learning, deep-learning, nlp\n",
      "   Preview: \n",
      "Transformeræ˜¯ç°ä»£NLPçš„åŸºç¡€æ¶æ„ï¼Œç”±Vaswaniç­‰äººåœ¨2017å¹´æå‡º(\"Attention is All You Need\")ã€‚\n",
      "\n",
      "æ ¸å¿ƒç»„ä»¶ï¼š\n",
      "1. **Self-Attentionæœº...\n",
      "\n",
      "2. è®¤çŸ¥å¤±è°ƒç†è®º (Cognitive Dissonance Theory) (score: 0.462)\n",
      "   Tags: psychology, cognitive-psychology, theories\n",
      "   Preview: \n",
      "è®¤çŸ¥å¤±è°ƒç†è®ºç”±Leon Festingeråœ¨1957å¹´æå‡ºã€‚å½“äººä»¬æŒæœ‰ä¸¤ä¸ªæˆ–å¤šä¸ªç›¸äº’çŸ›ç›¾çš„è®¤çŸ¥æ—¶ï¼Œä¼šäº§ç”Ÿå¿ƒç†ä¸é€‚ã€‚\n",
      "ä¸ºäº†å‡è½»è¿™ç§ä¸é€‚ï¼Œäººä»¬ä¼šï¼š\n",
      "1. æ”¹å˜è¡Œä¸º\n",
      "2. æ”¹å˜è®¤çŸ¥\n",
      "3. å¢åŠ æ–°çš„è®¤çŸ¥æ¥åˆ...\n",
      "\n",
      "3. åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„CAPå®šç† (score: 0.180)\n",
      "   Tags: computer-science, distributed-systems, theory\n",
      "   Preview: \n",
      "CAPå®šç†æŒ‡å‡ºï¼Œåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä»¥ä¸‹ä¸‰ä¸ªç‰¹æ€§æœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä¸¤ä¸ªï¼š\n",
      "\n",
      "**C (Consistency)**: ä¸€è‡´æ€§ - æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶é—´çœ‹åˆ°ç›¸åŒçš„æ•°æ®\n",
      "**A (Availability)**...\n",
      "\n",
      "4. test note (score: -0.008)\n",
      "   Tags: check\n",
      "   Preview: embedding check content...\n",
      "\n",
      "5. test note (score: -0.008)\n",
      "   Tags: check\n",
      "   Preview: embedding check content...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for notes about \"attention mechanism\" - should find the Transformer note\n",
    "search_query = {\n",
    "    \"query\": \"æ³¨æ„åŠ›æœºåˆ¶åœ¨ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨\",\n",
    "    \"limit\": 5\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/search\", json=search_query)\n",
    "results = response.json()\n",
    "\n",
    "print(f\"Search Results for: '{search_query['query']}'\")\n",
    "print(f\"Found {len(results['results'])} notes:\\n\")\n",
    "\n",
    "for i, result in enumerate(results['results'], 1):\n",
    "    print(f\"{i}. {result['title']} (score: {result['score']:.3f})\")\n",
    "    print(f\"   Tags: {', '.join(result['tags'])}\")\n",
    "    print(f\"   Preview: {result['content'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a36df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results for: 'test'\n",
      "Found 3 notes:\n",
      "\n",
      "Note ID: fb31fae2-e564-4cee-ae52-ad114c159984, Title: test note\n",
      "1. test note (score: 0.224)\n",
      "   Tags: check\n",
      "   Preview: embedding check content...\n",
      "\n",
      "2. è®¤çŸ¥å¤±è°ƒç†è®º (Cognitive Dissonance Theory) (score: 0.217)\n",
      "   Tags: psychology, cognitive-psychology, theories\n",
      "   Preview: \n",
      "è®¤çŸ¥å¤±è°ƒç†è®ºç”±Leon Festingeråœ¨1957å¹´æå‡ºã€‚å½“äººä»¬æŒæœ‰ä¸¤ä¸ªæˆ–å¤šä¸ªç›¸äº’çŸ›ç›¾çš„è®¤çŸ¥æ—¶ï¼Œä¼šäº§ç”Ÿå¿ƒç†ä¸é€‚ã€‚\n",
      "ä¸ºäº†å‡è½»è¿™ç§ä¸é€‚ï¼Œäººä»¬ä¼šï¼š\n",
      "1. æ”¹å˜è¡Œä¸º\n",
      "2. æ”¹å˜è®¤çŸ¥\n",
      "3. å¢åŠ æ–°çš„è®¤çŸ¥æ¥åˆ...\n",
      "\n",
      "3. åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„CAPå®šç† (score: 0.205)\n",
      "   Tags: computer-science, distributed-systems, theory\n",
      "   Preview: \n",
      "CAPå®šç†æŒ‡å‡ºï¼Œåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä»¥ä¸‹ä¸‰ä¸ªç‰¹æ€§æœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä¸¤ä¸ªï¼š\n",
      "\n",
      "**C (Consistency)**: ä¸€è‡´æ€§ - æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶é—´çœ‹åˆ°ç›¸åŒçš„æ•°æ®\n",
      "**A (Availability)**...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for notes about \"attention mechanism\" - should find the Transformer note\n",
    "search_query = {\n",
    "    \"query\": \"test\",\n",
    "    \"limit\": 3\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/search\", json=search_query)\n",
    "results = response.json()\n",
    "\n",
    "print(f\"Search Results for: '{search_query['query']}'\")\n",
    "print(f\"Found {len(results['results'])} notes:\\n\")\n",
    "for result in results['results']:\n",
    "    if 'test' in result['title'].lower():\n",
    "        print(f\"Note ID: {result['note_id']}, Title: {result['title']}\")\n",
    "for i, result in enumerate(results['results'], 1):\n",
    "    print(f\"{i}. {result['title']} (score: {result['score']:.3f})\")\n",
    "    print(f\"   Tags: {', '.join(result['tags'])}\")\n",
    "    print(f\"   Preview: {result['content'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee159149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter search by tags - only search within AI notes\n",
    "search_with_filter = {\n",
    "    \"query\": \"å¦‚ä½•å¤„ç†çŸ›ç›¾\",\n",
    "    \"limit\": 5,\n",
    "    \"tags\": [\"psychology\"]  # Only search in psychology notes\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/search\", json=search_with_filter)\n",
    "results = response.json()\n",
    "\n",
    "print(f\"Search Results (filtered by tags={search_with_filter['tags']}):\")\n",
    "print(f\"Found {len(results['results'])} notes:\\n\")\n",
    "\n",
    "for i, result in enumerate(results['results'], 1):\n",
    "    print(f\"{i}. {result['title']} (score: {result['score']:.3f})\")\n",
    "    print(f\"   Tags: {', '.join(result['tags'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858abd4",
   "metadata": {},
   "source": [
    "## 4. Update Notes\n",
    "\n",
    "All updates create new versions - the system tracks complete history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3281cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the note_id from the AI note we created earlier\n",
    "note_id = ai_result['note_id']\n",
    "\n",
    "# Add more information to the AI note\n",
    "update_data = {\n",
    "    \"content\": ai_note[\"content\"] + \"\"\"\n",
    "\n",
    "**æœ€æ–°å‘å±• (2024-2025)**ï¼š\n",
    "- Mixture of Experts (MoE): åªæ¿€æ´»éƒ¨åˆ†å‚æ•°ï¼Œæé«˜æ•ˆç‡\n",
    "- Flash Attention: ä¼˜åŒ–attentionè®¡ç®—ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨\n",
    "- Sparse Attention: ä¸æ˜¯æ‰€æœ‰tokenéƒ½éœ€è¦å…³æ³¨æ‰€æœ‰å…¶ä»–token\n",
    "- Long Context: æ”¯æŒ100K+tokensçš„è¶…é•¿ä¸Šä¸‹æ–‡çª—å£\n",
    "    \"\"\",\n",
    "    \"tags\": [\"ai\", \"machine-learning\", \"deep-learning\", \"nlp\", \"transformer\"]\n",
    "}\n",
    "\n",
    "response = requests.patch(f\"{BASE_URL}/notes/{note_id}\", json=update_data)\n",
    "update_result = response.json()\n",
    "\n",
    "print(\"Updated Note:\")\n",
    "print(f\"Note ID: {update_result['note_id']}\")\n",
    "print(f\"Version: {update_result['latest']['version']}\")\n",
    "print(f\"Content preview: {update_result['latest']['content'][:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91fb3192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted note fb31fae2-e564-4cee-ae52-ad114c159984\n",
      "Removed 1 version(s)\n"
     ]
    }
   ],
   "source": [
    "# Delete a note and all its versions\n",
    "note_id = \"fb31fae2-e564-4cee-ae52-ad114c159984\"\n",
    "response = requests.delete(f\"{BASE_URL}/notes/{note_id}\")\n",
    "result = response.json()\n",
    "\n",
    "print(f\"Deleted note {result['note_id']}\")\n",
    "print(f\"Removed {result['deleted_versions']} version(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0974f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version History for 'Transformer Architectureæ ¸å¿ƒæœºåˆ¶':\n",
      "Total versions: 1\n",
      "\n",
      "Version 1:\n",
      "  Created: 2025-12-30T16:00:10.718857+00:00\n",
      "  Content length: 23 chars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View all versions of a note\n",
    "note_id='fb31fae2-e564-4cee-ae52-ad114c159984'\n",
    "response = requests.get(f\"{BASE_URL}/notes/{note_id}/versions\")\n",
    "versions = response.json()\n",
    "\n",
    "print(f\"Version History for '{ai_note['title']}':\")\n",
    "print(f\"Total versions: {len(versions['versions'])}\\n\")\n",
    "\n",
    "for v in versions['versions']:\n",
    "    print(f\"Version {v['version']}:\")\n",
    "    print(f\"  Created: {v['created_at']}\")\n",
    "    print(f\"  Content length: {len(v['content'])} chars\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca3645",
   "metadata": {},
   "source": [
    "## 5. Verify Notes\n",
    "\n",
    "Mark notes as verified after you've reviewed and confirmed the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the psychology note\n",
    "psych_note_id = psych_result['note_id']\n",
    "\n",
    "verify_data = {\n",
    "    \"status\": \"verified\"  # Options: \"unverified\", \"verified\", \"needs_review\"\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/notes/{psych_note_id}/verify\", json=verify_data)\n",
    "verify_result = response.json()\n",
    "\n",
    "print(\"Verification Status:\")\n",
    "print(f\"Note: {verify_result['latest']['title']}\")\n",
    "print(f\"Status: {verify_result['latest']['status']}\")\n",
    "print(f\"Verified at: {verify_result['latest']['verified_at']}\")\n",
    "print(f\"Version: {verify_result['latest']['version']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19954ec3",
   "metadata": {},
   "source": [
    "## 6. Best Practices for Organization\n",
    "\n",
    "### Tag Strategy\n",
    "Organize your notes with a hierarchical tag system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2eb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended tag structure\n",
    "tag_examples = {\n",
    "    \"Psychology\": [\n",
    "        \"psychology\",                    # Main category\n",
    "        \"cognitive-psychology\",          # Sub-field\n",
    "        \"social-psychology\",\n",
    "        \"developmental-psychology\",\n",
    "        \"theories\",                      # Type of content\n",
    "        \"experiments\",\n",
    "        \"clinical-applications\"\n",
    "    ],\n",
    "    \n",
    "    \"Computer Science\": [\n",
    "        \"computer-science\",\n",
    "        \"algorithms\",                    # Sub-topics\n",
    "        \"data-structures\",\n",
    "        \"distributed-systems\",\n",
    "        \"databases\",\n",
    "        \"networking\",\n",
    "        \"tutorial\",                      # Content type\n",
    "        \"theory\",\n",
    "        \"practical\"\n",
    "    ],\n",
    "    \n",
    "    \"AI/Machine Learning\": [\n",
    "        \"ai\",\n",
    "        \"machine-learning\",\n",
    "        \"deep-learning\",                 # Specific areas\n",
    "        \"nlp\",\n",
    "        \"computer-vision\",\n",
    "        \"reinforcement-learning\",\n",
    "        \"paper-notes\",                   # Content type\n",
    "        \"implementation\",\n",
    "        \"research\"\n",
    "    ],\n",
    "    \n",
    "    \"Cross-cutting\": [\n",
    "        \"important\",                     # Priority\n",
    "        \"review-needed\",\n",
    "        \"draft\",\n",
    "        \"reference\",                     # Usage\n",
    "        \"tutorial\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Recommended Tag Structure:\")\n",
    "print(json.dumps(tag_examples, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ef2f8",
   "metadata": {},
   "source": [
    "### Tips for Effective Note-Taking\n",
    "\n",
    "1. **Use descriptive titles**: Make titles searchable and clear\n",
    "2. **Add source URLs**: Always link to original sources when available\n",
    "3. **Tag consistently**: Establish your tag vocabulary early\n",
    "4. **Update incrementally**: Don't delete - update and create new versions\n",
    "5. **Verify important notes**: Mark reviewed notes as verified\n",
    "6. **Use multilingual content**: The system handles Chinese and English seamlessly\n",
    "7. **Write rich content**: Include examples, code snippets, formulas\n",
    "8. **Search semantically**: Don't just match keywords - describe what you're looking for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d75d30",
   "metadata": {},
   "source": [
    "## 7. Advanced: Batch Operations\n",
    "\n",
    "Create a helper function to add multiple notes efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_note_batch(notes_list):\n",
    "    \"\"\"Create multiple notes at once\"\"\"\n",
    "    results = []\n",
    "    for note_data in notes_list:\n",
    "        response = requests.post(f\"{BASE_URL}/notes\", json=note_data)\n",
    "        if response.status_code == 200:\n",
    "            results.append(response.json())\n",
    "            print(f\"âœ“ Created: {note_data['title']}\")\n",
    "        else:\n",
    "            print(f\"âœ— Failed: {note_data['title']} - {response.text}\")\n",
    "    return results\n",
    "\n",
    "# Example: Add a series of related notes\n",
    "ml_basics = [\n",
    "    {\n",
    "        \"title\": \"æ¢¯åº¦ä¸‹é™ (Gradient Descent)\",\n",
    "        \"content\": \"ä¼˜åŒ–ç®—æ³•çš„åŸºç¡€ã€‚é€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œåå‘æ›´æ–°å‚æ•°ã€‚å­¦ä¹ ç‡æ§åˆ¶æ­¥é•¿ã€‚\",\n",
    "        \"tags\": [\"ai\", \"machine-learning\", \"optimization\", \"basics\"],\n",
    "        \"source_url\": None\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"åå‘ä¼ æ’­ (Backpropagation)\",\n",
    "        \"content\": \"é€šè¿‡é“¾å¼æ³•åˆ™è®¡ç®—æ¢¯åº¦ã€‚ä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚ä¼ æ’­è¯¯å·®ï¼Œé«˜æ•ˆè®¡ç®—æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ã€‚\",\n",
    "        \"tags\": [\"ai\", \"deep-learning\", \"neural-networks\", \"basics\"],\n",
    "        \"source_url\": None\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"è¿‡æ‹Ÿåˆä¸æ­£åˆ™åŒ–\",\n",
    "        \"content\": \"è¿‡æ‹Ÿåˆï¼šæ¨¡å‹åœ¨è®­ç»ƒé›†è¡¨ç°å¥½ä½†æ³›åŒ–èƒ½åŠ›å·®ã€‚è§£å†³æ–¹æ³•ï¼šL1/L2æ­£åˆ™åŒ–ã€Dropoutã€æ•°æ®å¢å¼ºã€Early Stoppingã€‚\",\n",
    "        \"tags\": [\"ai\", \"machine-learning\", \"regularization\", \"basics\"],\n",
    "        \"source_url\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "batch_results = create_note_batch(ml_basics)\n",
    "print(f\"\\nâœ“ Created {len(batch_results)} notes in batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10415fd",
   "metadata": {},
   "source": [
    "## 8. Export Notes\n",
    "\n",
    "You can retrieve and export your notes for backup or external use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f86bce",
   "metadata": {},
   "source": [
    "## 9. File Attachments (Optional)\n",
    "\n",
    "Attach original files to notes for reference (in addition to extracting text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745562ea",
   "metadata": {},
   "source": [
    "## 8. Ingest Files as Notes\n",
    "\n",
    "Automatically convert files (PDF papers, HTML articles, code, etc.) into searchable notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Ingest a text file\n",
    "sample_text = \"\"\"\n",
    "# Understanding Attention Mechanisms\n",
    "\n",
    "Attention mechanisms allow neural networks to focus on relevant parts of the input.\n",
    "The key innovation is computing weighted combinations of input features.\n",
    "\n",
    "Key concepts:\n",
    "- Query, Key, Value paradigm\n",
    "- Scaled dot-product attention\n",
    "- Multi-head attention for diverse representations\n",
    "\n",
    "Applications: machine translation, text summarization, question answering.\n",
    "\"\"\"\n",
    "\n",
    "# Save sample file\n",
    "with open(\"attention_tutorial.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "# Ingest the file\n",
    "with open(\"attention_tutorial.txt\", \"rb\") as f:\n",
    "    files = {\"file\": f}\n",
    "    data = {\"tags\": \"ai,tutorial\"}\n",
    "    response = requests.post(f\"{BASE_URL}/ingest\", files=files, data=data)\n",
    "\n",
    "ingest_result = response.json()\n",
    "print(\"Ingested file as note:\")\n",
    "print(f\"Title: {ingest_result['title']}\")\n",
    "print(f\"Note ID: {ingest_result['note_id']}\")\n",
    "print(f\"Extracted length: {ingest_result['extracted_length']} chars\")\n",
    "print(f\"Suggested tags: {ingest_result['suggested_tags']}\")\n",
    "print(f\"Final tags: {ingest_result['latest']['tags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Ingest HTML article\n",
    "sample_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head><title>Cognitive Load Theory</title></head>\n",
    "<body>\n",
    "<h1>Cognitive Load Theory in Learning</h1>\n",
    "<p>Cognitive Load Theory (CLT), developed by John Sweller, focuses on the amount of \n",
    "information working memory can hold at one time.</p>\n",
    "\n",
    "<h2>Types of Cognitive Load</h2>\n",
    "<ul>\n",
    "<li><strong>Intrinsic Load</strong>: Inherent difficulty of the material</li>\n",
    "<li><strong>Extraneous Load</strong>: How information is presented</li>\n",
    "<li><strong>Germane Load</strong>: Mental effort for schema construction</li>\n",
    "</ul>\n",
    "\n",
    "<p>Effective instructional design minimizes extraneous load while managing intrinsic load.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"cognitive_load.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_html)\n",
    "\n",
    "# Ingest HTML file - text will be extracted automatically\n",
    "with open(\"cognitive_load.html\", \"rb\") as f:\n",
    "    files = {\"file\": f}\n",
    "    data = {\"tags\": \"psychology,learning\"}\n",
    "    response = requests.post(f\"{BASE_URL}/ingest\", files=files, data=data)\n",
    "\n",
    "html_result = response.json()\n",
    "print(\"Ingested HTML file:\")\n",
    "print(f\"Title: {html_result['title']}\")\n",
    "print(f\"Content preview: {html_result['latest']['content'][:200]}...\")\n",
    "print(f\"Tags: {html_result['latest']['tags']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42805adb",
   "metadata": {},
   "source": [
    "### Supported File Formats\n",
    "\n",
    "**Automatic text extraction for:**\n",
    "- **Text files**: `.txt`, `.md`, `.py`, `.js`, `.java`, `.cpp`, `.c`, `.h`\n",
    "- **HTML**: `.html`, `.htm` - strips tags, extracts text\n",
    "- **PDF**: `.pdf` - extracts text from all pages (requires `pypdf`)\n",
    "- **Code files**: Preserves formatting\n",
    "\n",
    "**Auto-tagging:**\n",
    "The system automatically suggests tags based on:\n",
    "- File extension (code, document, web, paper)\n",
    "- Content analysis (research, computer-science, ai)\n",
    "- Keywords detection\n",
    "\n",
    "**Batch ingestion example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a02c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch ingest multiple files from a directory\n",
    "from pathlib import Path\n",
    "\n",
    "def ingest_directory(directory, tags=\"\"):\n",
    "    \"\"\"Ingest all supported files from a directory\"\"\"\n",
    "    results = []\n",
    "    dir_path = Path(directory)\n",
    "    \n",
    "    for file_path in dir_path.glob(\"**/*\"):\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        \n",
    "        # Skip common non-text files\n",
    "        if file_path.suffix.lower() in ['.pyc', '.class', '.o', '.exe', '.jpg', '.png', '.gif']:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                files = {\"file\": (file_path.name, f)}\n",
    "                data = {\"tags\": tags}\n",
    "                response = requests.post(f\"{BASE_URL}/ingest\", files=files, data=data)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    results.append(result)\n",
    "                    print(f\"âœ“ {file_path.name} â†’ {result['title']}\")\n",
    "                else:\n",
    "                    print(f\"âœ— {file_path.name} - {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {file_path.name} - {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: ingest all files in current directory\n",
    "# ingested_notes = ingest_directory(\"./my_papers\", tags=\"research,to-review\")\n",
    "print(\"Batch ingestion function ready. Use: ingest_directory('./path/to/files', 'your,tags')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file to a note\n",
    "# First, create a sample file for demonstration\n",
    "sample_pdf_content = b\"%PDF-1.4 Sample PDF content for demonstration\"\n",
    "with open(\"sample_paper.pdf\", \"wb\") as f:\n",
    "    f.write(sample_pdf_content)\n",
    "\n",
    "# Upload the file to a note\n",
    "note_id_for_file = ai_result['note_id']  # Use the AI note we created earlier\n",
    "\n",
    "with open(\"sample_paper.pdf\", \"rb\") as f:\n",
    "    files = {\"file\": (\"transformer_paper.pdf\", f, \"application/pdf\")}\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/notes/{note_id_for_file}/files\",\n",
    "        files=files\n",
    "    )\n",
    "\n",
    "upload_result = response.json()\n",
    "print(\"File uploaded:\")\n",
    "print_json(upload_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19688cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files attached to a note\n",
    "response = requests.get(f\"{BASE_URL}/notes/{note_id_for_file}/files\")\n",
    "files_list = response.json()\n",
    "\n",
    "print(f\"Files attached to note:\")\n",
    "for file_info in files_list['files']:\n",
    "    print(f\"  - {file_info['filename']} ({file_info['size']} bytes)\")\n",
    "    print(f\"    Type: {file_info['content_type']}\")\n",
    "    print(f\"    File ID: {file_info['file_id']}\")\n",
    "    print(f\"    Uploaded: {file_info['uploaded_at']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203084d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a file\n",
    "file_id = upload_result['file_id']\n",
    "download_url = f\"{BASE_URL}/files/{note_id_for_file}/{file_id}\"\n",
    "\n",
    "response = requests.get(download_url)\n",
    "if response.status_code == 200:\n",
    "    # Save downloaded file\n",
    "    with open(\"downloaded_paper.pdf\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"âœ“ Downloaded file: {response.headers.get('content-disposition', 'unknown')}\")\n",
    "    print(f\"  Size: {len(response.content)} bytes\")\n",
    "else:\n",
    "    print(f\"âœ— Download failed: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8504bb",
   "metadata": {},
   "source": [
    "### Practical File Use Cases\n",
    "\n",
    "**Research Papers (PDF)**\n",
    "```python\n",
    "with open(\"attention_is_all_you_need.pdf\", \"rb\") as f:\n",
    "    files = {\"file\": (\"attention_paper.pdf\", f, \"application/pdf\")}\n",
    "    requests.post(f\"{BASE_URL}/notes/{note_id}/files\", files=files)\n",
    "```\n",
    "\n",
    "**Web Articles (HTML)**\n",
    "```python\n",
    "with open(\"saved_article.html\", \"rb\") as f:\n",
    "    files = {\"file\": (\"article.html\", f, \"text/html\")}\n",
    "    requests.post(f\"{BASE_URL}/notes/{note_id}/files\", files=files)\n",
    "```\n",
    "\n",
    "**Code Examples**\n",
    "```python\n",
    "with open(\"implementation.py\", \"rb\") as f:\n",
    "    files = {\"file\": (\"transformer_impl.py\", f, \"text/x-python\")}\n",
    "    requests.post(f\"{BASE_URL}/notes/{note_id}/files\", files=files)\n",
    "```\n",
    "\n",
    "**Images/Diagrams**\n",
    "```python\n",
    "with open(\"architecture_diagram.png\", \"rb\") as f:\n",
    "    files = {\"file\": (\"diagram.png\", f, \"image/png\")}\n",
    "    requests.post(f\"{BASE_URL}/notes/{note_id}/files\", files=files)\n",
    "```\n",
    "\n",
    "Files are versioned with notes - each update creates a new version preserving the attachment list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea288df",
   "metadata": {},
   "source": [
    "## 10. Export Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def export_notes_by_tag(tag, output_format=\"json\"):\n",
    "    \"\"\"Export all notes with a specific tag\"\"\"\n",
    "    # Search for all notes with the tag\n",
    "    search_query = {\"query\": tag, \"limit\": 100, \"tags\": [tag]}\n",
    "    response = requests.post(f\"{BASE_URL}/search\", json=search_query)\n",
    "    results = response.json()['results']\n",
    "    \n",
    "    if output_format == \"json\":\n",
    "        filename = f\"notes_{tag}_{datetime.now().strftime('%Y%m%d')}.json\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"âœ“ Exported {len(results)} notes to {filename}\")\n",
    "        \n",
    "    elif output_format == \"markdown\":\n",
    "        filename = f\"notes_{tag}_{datetime.now().strftime('%Y%m%d')}.md\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# Notes: {tag}\\n\\n\")\n",
    "            f.write(f\"Exported: {datetime.now().isoformat()}\\n\")\n",
    "            f.write(f\"Total notes: {len(results)}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "            \n",
    "            for note in results:\n",
    "                f.write(f\"## {note['title']}\\n\\n\")\n",
    "                f.write(f\"**Tags**: {', '.join(note['tags'])}\\n\\n\")\n",
    "                if note.get('source_url'):\n",
    "                    f.write(f\"**Source**: {note['source_url']}\\n\\n\")\n",
    "                f.write(f\"{note['content']}\\n\\n\")\n",
    "                f.write(\"---\\n\\n\")\n",
    "        print(f\"âœ“ Exported {len(results)} notes to {filename}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Export all AI-related notes as Markdown\n",
    "ai_notes = export_notes_by_tag(\"ai\", output_format=\"markdown\")\n",
    "print(f\"Exported {len(ai_notes)} AI notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ffaad",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now know how to:\n",
    "- âœ… Create notes with tags for different categories\n",
    "- âœ… Search notes semantically (meaning-based, not just keywords)\n",
    "- âœ… Filter searches by tags\n",
    "- âœ… Update notes with automatic versioning\n",
    "- âœ… View version history\n",
    "- âœ… Verify notes after review\n",
    "- âœ… Batch create multiple notes\n",
    "- âœ… Export notes to JSON or Markdown\n",
    "\n",
    "### Next Steps\n",
    "1. Start creating notes in your areas of interest\n",
    "2. Develop a consistent tagging system\n",
    "3. Use semantic search to rediscover knowledge\n",
    "4. Export important notes for backup\n",
    "\n",
    "### API Reference\n",
    "- `POST /notes` - Create a new note\n",
    "- `GET /notes/{note_id}` - Get latest version of a note\n",
    "- `PATCH /notes/{note_id}` - Update a note (creates new version)\n",
    "- `GET /notes/{note_id}/versions` - View all versions\n",
    "- `POST /notes/{note_id}/verify` - Change verification status\n",
    "- `POST /search` - Semantic search with optional tag filtering\n",
    "- `GET /health` - Check API status\n",
    "\n",
    "Enjoy your knowledge management! ğŸ“š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
